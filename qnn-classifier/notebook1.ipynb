{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:18:04.179275800Z",
     "start_time": "2025-12-19T11:18:04.168221Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = fetch_openml(name=\"ionosphere\", version=1, as_frame=False)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Encode labels: g -> 1, b -> -1\n",
    "y = np.array([1 if label == \"g\" else -1 for label in y])\n",
    "\n",
    "# Normalize features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# PCA: 34 â†’ 4 features\n",
    "pca = PCA(n_components=4)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:18:07.794831900Z",
     "start_time": "2025-12-19T11:18:07.752603100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "n_layers = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:18:10.702075500Z",
     "start_time": "2025-12-19T11:18:10.694920300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def encode_features(x):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(np.pi * x[i], wires=i)\n",
    "\n",
    "def variational_circuit(weights):\n",
    "    for layer in range(n_layers):\n",
    "        for q in range(n_qubits):\n",
    "            qml.RY(weights[layer, q, 0], wires=q)\n",
    "            qml.RZ(weights[layer, q, 1], wires=q)\n",
    "\n",
    "        # Entanglement\n",
    "        for q in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[q, q + 1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:18:11.668885700Z",
     "start_time": "2025-12-19T11:18:11.657755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def vqc(x, weights):\n",
    "    encode_features(x)\n",
    "    variational_circuit(weights)\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:26:57.812958200Z",
     "start_time": "2025-12-19T11:26:57.790234100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def predict(x, weights):\n",
    "    return np.mean(vqc(x, weights))\n",
    "\n",
    "def loss(weights, X, y):\n",
    "    preds = np.array([vqc(x, weights) for x in X])\n",
    "    return np.mean(np.log(1 + np.exp(-y * preds)))\n",
    "\n",
    "def accuracy(X, y, weights):\n",
    "    preds = np.sign([vqc(x, weights) for x in X])\n",
    "    return np.mean(preds == y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:26:58.462923300Z",
     "start_time": "2025-12-19T11:26:58.454722600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (280,) (280,4) ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m epochs = \u001B[32m40\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     weights = \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m epoch % \u001B[32m5\u001B[39m == \u001B[32m0\u001B[39m:\n\u001B[32m     13\u001B[39m         train_loss = loss(weights, X_train, y_train)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\quantum_ai\\venv\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:93\u001B[39m, in \u001B[36mGradientDescentOptimizer.step\u001B[39m\u001B[34m(self, objective_fn, grad_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     75\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, objective_fn, *args, grad_fn=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m     76\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001B[39;00m\n\u001B[32m     77\u001B[39m \n\u001B[32m     78\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     90\u001B[39m \u001B[33;03m        If single arg is provided, list [array] is replaced by array.\u001B[39;00m\n\u001B[32m     91\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     g, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgrad_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     94\u001B[39m     new_args = \u001B[38;5;28mself\u001B[39m.apply_grad(g, args)\n\u001B[32m     96\u001B[39m     \u001B[38;5;66;03m# unwrap from list if one argument, cleaner return\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\quantum_ai\\venv\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:122\u001B[39m, in \u001B[36mGradientDescentOptimizer.compute_grad\u001B[39m\u001B[34m(objective_fn, args, kwargs, grad_fn)\u001B[39m\n\u001B[32m    104\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Compute the gradient of the objective function at the given point and return it along with\u001B[39;00m\n\u001B[32m    105\u001B[39m \u001B[33;03mthe objective function forward pass (if available).\u001B[39;00m\n\u001B[32m    106\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    119\u001B[39m \u001B[33;03m    will not be evaluated and instead ``None`` will be returned.\u001B[39;00m\n\u001B[32m    120\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    121\u001B[39m g = get_gradient(objective_fn) \u001B[38;5;28;01mif\u001B[39;00m grad_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m grad_fn\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m grad = \u001B[43mg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    123\u001B[39m forward = \u001B[38;5;28mgetattr\u001B[39m(g, \u001B[33m\"\u001B[39m\u001B[33mforward\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    125\u001B[39m num_trainable_args = \u001B[38;5;28msum\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(arg, \u001B[33m\"\u001B[39m\u001B[33mrequires_grad\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\quantum_ai\\venv\\Lib\\site-packages\\pennylane\\_grad.py:315\u001B[39m, in \u001B[36mgrad.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    309\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(argnum, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m argnum:\n\u001B[32m    310\u001B[39m     warnings.warn(\n\u001B[32m    311\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAttempted to differentiate a function with no trainable parameters. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    312\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mIf this is unintended, please add trainable parameters via the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    313\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[33mrequires_grad\u001B[39m\u001B[33m'\u001B[39m\u001B[33m attribute or \u001B[39m\u001B[33m'\u001B[39m\u001B[33margnum\u001B[39m\u001B[33m'\u001B[39m\u001B[33m keyword.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    314\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m     \u001B[38;5;28mself\u001B[39m._forward = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    316\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ()\n\u001B[32m    318\u001B[39m grad_value, ans = grad_fn(*args, **kwargs)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36m<lambda>\u001B[39m\u001B[34m(w)\u001B[39m\n\u001B[32m      7\u001B[39m epochs = \u001B[32m40\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     weights = optimizer.step(\u001B[38;5;28;01mlambda\u001B[39;00m w: \u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m, weights)\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m epoch % \u001B[32m5\u001B[39m == \u001B[32m0\u001B[39m:\n\u001B[32m     13\u001B[39m         train_loss = loss(weights, X_train, y_train)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mloss\u001B[39m\u001B[34m(weights, X, y)\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mloss\u001B[39m(weights, X, y):\n\u001B[32m      5\u001B[39m     preds = np.array([vqc(x, weights) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m X])\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.mean(np.log(\u001B[32m1\u001B[39m + np.exp(\u001B[43m-\u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreds\u001B[49m)))\n",
      "\u001B[31mValueError\u001B[39m: operands could not be broadcast together with shapes (280,) (280,4) "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Weights shape: (layers, qubits, params)\n",
    "weights = np.random.normal(0, 0.1, size=(n_layers, n_qubits, 2))\n",
    "\n",
    "optimizer = qml.AdamOptimizer(stepsize=0.05)\n",
    "epochs = 40\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    weights = optimizer.step(lambda w: loss(w, X_train, y_train), weights)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        train_loss = loss(weights, X_train, y_train)\n",
    "        print(f\"Epoch {epoch:02d} | Loss: {train_loss:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:27:00.890282700Z",
     "start_time": "2025-12-19T11:26:59.721506400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results\n",
      "Train Accuracy: 0.48928571428571427\n",
      "Test Accuracy: 0.4507042253521127\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(X_train, y_train, weights)\n",
    "test_acc = accuracy(X_test, y_test, weights)\n",
    "\n",
    "print(\"\\nFinal Results\")\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-19T11:23:57.180000200Z",
     "start_time": "2025-12-19T11:23:56.158518900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
